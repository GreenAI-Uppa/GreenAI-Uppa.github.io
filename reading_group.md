---
title: 
feature_text: |
  ## GreenAI UPPA 
feature_text_logo: "/assets/horizontal_dark_logo.png"
feature_image: "/assets/ossau_lurien_bright.png"
excerpt: "Longer intro"
aside: true 
---

In this page, you will find all the previous reading group session.

### 2022 Q2: 30/05/22
- *Tiny ML : Machine Learning for embedded systems* by Yanis
<a href="/images/reading/vague-mai-2022/presentation_arduino.pdf">Slides here</a>

- *RPi cluster & Deep Learning* by Fatou Kiné
<a href="/images/reading/vague-mai-2022/RPI_CLUSTER-2.pdf">Slides here</a>

- *Nvidia Jetson Nano* by Nicolas
<a href="/images/reading/vague-mai-2022/Reading_group_Jetson.pdf">Slides here</a>

### 2022 Q2: 28/03/22

- *Sparse matrix multiplication with pytorch and Cuda* by Nicolas and Yanis (14h)

- *Inference using tflite with larq* by Fatou (14h30)

- *Social computing : NLP and community detection* by Matthieu and Paul (15h)
<a href="/images/reading/vague-mars-2022/reading_matt_28_3.pdf">Slides here</a>

- *Greedy decentralized optimization for deep learning* by Simon (16h00)

- *Convergence of MH algorithm for deep learning* by Jordy (16h30)



### 2022 Q1: 24/01/22

- *Binarization of Neural Networks* by Fatou Kiné Sow & Matthieu François 

<a href="/images/reading/vague-janvier-2022/BNN.pdf">Slides here</a>

[1] « XNOR-Net: ImageNet Classification Using Binary
Convolutional Neural Networks », M. Rastegari, V. Ordonez, J. Redmon, A. Farhadi. See the full article <a href="https://arxiv.org/pdf/1603.05279.pdf ">here</a>. 
<p float="left">
  <a href="/images/reading/vague-janvier-2022/mf/PXL_20220131_095525754.jpg" target="_blank">
    <img src="/images/reading/vague-janvier-2022/mf/PXL_20220131_095525754.jpg" alt="alt text" title="handwritten note 1" width="150"/>
  </a>
  <a href="/images/reading/vague-janvier-2022/mf/PXL_20220131_095539290.jpg" target="_blank">
    <img src="/images/reading/vague-janvier-2022/mf/PXL_20220131_095539290.jpg" alt="alt text" title="handwritten note 2" width="150"/>
  </a>
</p>

[2] « XNOR-Net++: Improved binary neural networks » , A. Bulat, G. Tzimiropoulos. See the full article <a href="https://arxiv.org/pdf/1909.13863.pdf">here</a>. 


[3] « BinaryConnect: Training Deep Neural Networks with binary weights during propagations »,  M. Courbariaux, Y. Bengio, J-P. David. See the full article <a href="https://arxiv.org/pdf/1511.00363.pdf">here</a>. 

[4] « Binarized Neural Networks: Training Neural Networks with Weights and Activations Constrained to +1 or −1 », M. Courbariaux, I. Hubara, D. Soudry, R. El-Yaniv, Y. Bengio. See the full article <a href="https://arxiv.org/pdf/1602.02830.pdf">here</a>. 

<div style="margin-top:0px;margin-bottom:40px;height:1px;width:70px;margin:20px auto 25px;background:#ebebeb;display:block;border:none;"></div>

- *Early Exit and Device to Cloud* by Simon Lebeaud

<a href="/images/reading/vague-janvier-2022/EarlyExits.pdf">Slides here</a>

For more details, see :

[1] « Multi-scale dense networkds for resource efficient image classification » , G. Huang, D. Chen,T. Li, F. Wu
L. van der Maaten, K. Weinberger. See the full article <a href="https://arxiv.org/pdf/1703.09844.pdf">here</a>.

[2] « SPINN : Synergistic Progressive Inference of Neural Networks over device and cloud », S. Laskaridis, S. I. Venieris,
M. Almeida, I. Leontiadis, N. D. Lane. See the full article <a href="https://arxiv.org/pdf/2008.06402.pdf">here</a>.




<div style="margin-top:0px;margin-bottom:40px;height:1px;width:70px;margin:20px auto 25px;background:#ebebeb;display:block;border:none;"></div>

- *Pruning* by Nicolas Tirel & Yanis Chaigneau

See the Jupyter-notebook <a href="/images/reading/vague-janvier-2022/Pruning_SNIP_FORCE/Force_pruning.ipynb">here</a>.

[1] « Skeletonization: A Technique for Trimming the Fat from a Network via Relevance Assessment », M. C. Mozer et P. Smolensky, 1988.
See the complete <a href="https://www.semanticscholar.org/paper/Skeletonization%3A-A-Technique-for-Trimming-the-Fat-a-Mozer-Smolensky/a87953825b0bea2a5d52bfccf09d2518295c5053">article</a>. 


[2] « SNIP: Single-shot Network Pruning based on Connection Sensitivity », N. Lee, T. Ajanthan, P. H. S. Torr. See the full article <a href="http://arxiv.org/abs/1810.02340">here</a>.


[3] « Progressive Skeletonization: Trimming more fat from a network at initialization », P. de Jorge, A. Sanyal, H. S. Behl, P. H. S. Torr, G. Rogez, et P. K. Dokania,  March 2021. See the full article <a href="http://arxiv.org/abs/2006.09081">here</a>.


<div style="margin-top:0px;margin-bottom:40px;height:1px;width:70px;margin:20px auto 25px;background:#ebebeb;display:block;border:none;"></div>

- *Pruning with budget* and *Regularization* : Jordy Palafox
[1] « Deep Rewiring: Training very sparse deep networks », G. Bellec, D. Kappel, W. Maass, R. Legenstein. See the full article <a href="https://arxiv.org/pdf/1711.05136.pdf">here</a>.

[2] « Statistical guarantees for regularized neural networks », M. Taheri, F. Xie, J. Lederer. See the full article <a href="https://www.sciencedirect.com/science/article/pii/S0893608021001714">here</a>.

<div style="margin-top:0px;margin-bottom:40px;height:1px;width:70px;margin:20px auto 25px;background:#ebebeb;display:block;border:none;"></div>


### 2021 Q4: 29/10/2021

- *Metrical Task System, Online Learning and Power Management* by Matthieu François :

[1] « On-line Learning and the Metrical Task System Problem », A. Blum, C. Burch. See the full article <a href="https://link.springer.com/article/10.1023/A:1007621832648">here</a>.


[2] « Online Strategies for Dynamic Power Management in Systems with Multiple Power-Saving States », S. Irani, S. Shukla, R. Gupta. See the full <a href="https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.215.8295&rep=rep1&type=pdf">article</a>.


<p float="left">
  <a href="/images/reading/vague-octobre-2021/mf/PXL_20220131_095753838.jpg" target="_blank">
    <img src="/images/reading/vague-octobre-2021/mf/PXL_20220131_095753838.jpg" alt="alt text" title="handwritten note 1" width="150"/>
  </a>
  <a href="/images/reading/vague-octobre-2021/mf/PXL_20220131_095800957.jpg" target="_blank">
    <img src="/images/reading/vague-octobre-2021/mf/PXL_20220131_095800957.jpg" alt="alt text" title="handwritten note 2" width="150"/>
  </a>
</p>

<div style="margin-top:0px;margin-bottom:40px;height:1px;width:70px;margin:20px auto 25px;background:#ebebeb;display:block;border:none;"></div>

- *Metrical Task System and K-server problem* by Jordy Palafox :

[1] « An Optimal On-Line Algorithm for Metrical Task System », A. Borodin, N. Linial, M.E. Saks. See the full article <a href="https://www.cs.huji.ac.il/~nati/PAPERS/bls_online.pdf">here</a>.


[2]
« Competitive Algorithms for Server Problems », M.S. Manasse, L.A. McGeoch, D.D. Sleator. Journal of algrithms 11, 208-230 (1990). See the full article <a href="https://www.sciencedirect.com/science/article/pii/019667749090003W">here</a>.

<p float="left">
  <a href="/images/reading/vague-octobre-2021/jp/IMG_1989.jpg" target="_blank">
    <img src="/images/reading/vague-octobre-2021/jp/IMG_1989.jpg" alt="alt text" title="handwritten note 1" width="150"/>
  </a>
  <a href="/images/reading/vague-octobre-2021/jp/IMG_1990.jpg" target="_blank">
    <img src="/images/reading/vague-octobre-2021/jp/IMG_1990.jpg" alt="alt text" title="handwritten note 2" width="150"/>
  </a>
  <a href="/images/reading/vague-octobre-2021/jp/IMG_1991.jpg" target="_blank">
    <img src="/images/reading/vague-octobre-2021/jp/IMG_1991.jpg" alt="alt text" title="handwritten note 3" width="150"/>
  </a>
</p>

### Contact

You want to join the team ? Feel free to contact us if you want to contribute: contact [Paul](mailto:paul.gay@univ-pau.fr) or [Sébastien](https://sebastienloustau.github.io)
